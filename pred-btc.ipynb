{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #csv file 불러오기\n",
    "import numpy as np #행렬연산\n",
    "import matplotlib.pyplot as plt #시각화\n",
    "from keras.models import Sequential #keras 딥러닝모델\n",
    "from keras.layers import LSTM, Dropout, Dense, Activation\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Market Cap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29-Apr-13</td>\n",
       "      <td>134</td>\n",
       "      <td>147</td>\n",
       "      <td>134</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>1603768865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30-Apr-13</td>\n",
       "      <td>144</td>\n",
       "      <td>147</td>\n",
       "      <td>134</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>1542813125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-May-13</td>\n",
       "      <td>139</td>\n",
       "      <td>140</td>\n",
       "      <td>108</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>1298954594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02-May-13</td>\n",
       "      <td>116</td>\n",
       "      <td>126</td>\n",
       "      <td>92</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>1168517495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03-May-13</td>\n",
       "      <td>106</td>\n",
       "      <td>108</td>\n",
       "      <td>79</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>1085995169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Open  High  Low  Close  Volume  Market Cap\n",
       "0  29-Apr-13   134   147  134    145       0  1603768865\n",
       "1  30-Apr-13   144   147  134    139       0  1542813125\n",
       "2  01-May-13   139   140  108    117       0  1298954594\n",
       "3  02-May-13   116   126   92    105       0  1168517495\n",
       "4  03-May-13   106   108   79     98       0  1085995169"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r'D:/shinj/Data/[1]pred-bitcoin/Data/bitcoin.csv') #csv데이터셋 로드\n",
    "data.head() #상위 5라인 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_prices = data['High'].values #최고값 저장\n",
    "low_prices = data['Low'].values #최저값 저장\n",
    "mid_prices = (high_prices + low_prices) / 2 #csv데이터에 , 가 있으면 연산불가, 중간가격 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#윈도우생성\n",
    "seq_len = 50 #윈도우사이즈 50(50일의 데이터를 확인후 다음날짜 예측)\n",
    "sequence_length = seq_len + 1 #50일+1(다음날짜)\n",
    "\n",
    "result = [] #result변수에 51개씩 저장\n",
    "for index in range(len(mid_prices) - sequence_length):\n",
    "    result.append(mid_prices[index: index + sequence_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2361, 50, 1), (262, 50, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터 정규화\n",
    "def normalize_windows(data):\n",
    "    normalized_data = []\n",
    "    \n",
    "    for window in data:\n",
    "        normalized_window = [((float(p) / float(window[0])) - 1) for p in window]\n",
    "        #첫번째 윈도우값0 기준,(현재날짜/이전날짜)-1\n",
    "        normalized_data.append(normalized_window)\n",
    "    return np.array(normalized_data)\n",
    "\n",
    "result = normalize_windows(result) #정규화 결과값 저장\n",
    "\n",
    "#트레이닝 데이터셋0.9 / 테스트 데이터셋 0.1\n",
    "row = int(round(result.shape[0] * 0.9))\n",
    "train = result[:row, :]\n",
    "np.random.shuffle(train) # 트레이닝데이터셋 랜덤셔플(예측의 적응대비)\n",
    "\n",
    "x_train = train[:, :-1]#0.9 트레이닝데이터\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "y_train = train[:, -1]#0.1 테스트데이터\n",
    "\n",
    "x_test = result[row:, :-1]#0.9 트레이닝데이터\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "y_test = result[row:, -1]#0.1 테스트데이터\n",
    "\n",
    "x_train.shape, x_test.shape\n",
    "#2361일의 데이터로 262일의 값예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 50, 50)            10400     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 39,905\n",
      "Trainable params: 39,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()#모델을 순차적으로 정의\n",
    "\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(50, 1)))\n",
    "\n",
    "model.add(LSTM(64, return_sequences=False))#조정하면서 성능파악\n",
    "\n",
    "model.add(Dense(1, activation='linear'))#다음날 1일 예측\n",
    "\n",
    "model.compile(loss='mse', optimizer='rmsprop')\n",
    "\n",
    "model.summary()#개요출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  1/237 [..............................] - ETA: 0s - loss: 0.1044WARNING:tensorflow:From C:\\Users\\shinj\\anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "  2/237 [..............................] - ETA: 3:32 - loss: 0.1297WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0745s vs `on_train_batch_end` time: 1.7291s). Check your callbacks.\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0629\n",
      "Epoch 00001: val_loss improved from inf to 0.00429, saving model to ./models\\2020_09_28_00_21_09_eth.h5\n",
      "237/237 [==============================] - 16s 67ms/step - loss: 0.0629 - val_loss: 0.0043\n",
      "Epoch 2/20\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.0300\n",
      "Epoch 00002: val_loss did not improve from 0.00429\n",
      "237/237 [==============================] - 11s 46ms/step - loss: 0.0300 - val_loss: 0.0054\n",
      "Epoch 3/20\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0215\n",
      "Epoch 00003: val_loss did not improve from 0.00429\n",
      "237/237 [==============================] - 11s 45ms/step - loss: 0.0215 - val_loss: 0.0048\n",
      "Epoch 4/20\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0215\n",
      "Epoch 00004: val_loss improved from 0.00429 to 0.00360, saving model to ./models\\2020_09_28_00_21_09_eth.h5\n",
      "237/237 [==============================] - 11s 46ms/step - loss: 0.0215 - val_loss: 0.0036\n",
      "Epoch 5/20\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.0196\n",
      "Epoch 00005: val_loss improved from 0.00360 to 0.00295, saving model to ./models\\2020_09_28_00_21_09_eth.h5\n",
      "237/237 [==============================] - 10s 43ms/step - loss: 0.0196 - val_loss: 0.0030\n",
      "Epoch 6/20\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.0181\n",
      "Epoch 00006: val_loss improved from 0.00295 to 0.00249, saving model to ./models\\2020_09_28_00_21_09_eth.h5\n",
      "237/237 [==============================] - 11s 45ms/step - loss: 0.0181 - val_loss: 0.0025\n",
      "Epoch 7/20\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.0136- ETA: 0s -\n",
      "Epoch 00007: val_loss did not improve from 0.00249\n",
      "237/237 [==============================] - 11s 47ms/step - loss: 0.0136 - val_loss: 0.0049\n",
      "Epoch 8/20\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.0129\n",
      "Epoch 00008: val_loss improved from 0.00249 to 0.00160, saving model to ./models\\2020_09_28_00_21_09_eth.h5\n",
      "237/237 [==============================] - 11s 46ms/step - loss: 0.0129 - val_loss: 0.0016\n",
      "Epoch 9/20\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0107\n",
      "Epoch 00009: val_loss did not improve from 0.00160\n",
      "237/237 [==============================] - 11s 45ms/step - loss: 0.0107 - val_loss: 0.0016\n",
      "Epoch 10/20\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0101\n",
      "Epoch 00010: val_loss did not improve from 0.00160\n",
      "237/237 [==============================] - 11s 45ms/step - loss: 0.0101 - val_loss: 0.0036\n",
      "Epoch 11/20\n",
      "236/237 [============================>.] - ETA: 0s - loss: 0.0097\n",
      "Epoch 00011: val_loss improved from 0.00160 to 0.00146, saving model to ./models\\2020_09_28_00_21_09_eth.h5\n",
      "237/237 [==============================] - 10s 43ms/step - loss: 0.0097 - val_loss: 0.0015\n",
      "Epoch 12/20\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.0086\n",
      "Epoch 00012: val_loss did not improve from 0.00146\n",
      "237/237 [==============================] - 11s 44ms/step - loss: 0.0086 - val_loss: 0.0021\n",
      "Epoch 13/20\n",
      "189/237 [======================>.......] - ETA: 2s - loss: 0.0098"
     ]
    }
   ],
   "source": [
    "start_time = datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "#트레이닝\n",
    "model.fit(x_train, y_train,\n",
    "    validation_data=(x_test, y_test),\n",
    "    batch_size=10, #한번에 학습시킬 묶음\n",
    "    epochs=20, #20번동안 반복학습\n",
    "    callbacks=[\n",
    "        TensorBoard(log_dir='logs/%s' % (start_time)),\n",
    "        ModelCheckpoint('./models/%s_eth.h5' % (start_time), monitor='val_loss', verbose=1, save_best_only=True, mode='auto'),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, verbose=1, mode='auto')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#검증및 가시화\n",
    "pred = model.predict(x_test)#모델을 사용해 예측\n",
    "\n",
    "fig = plt.figure(facecolor='white', figsize=(20, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(y_test, label='True')\n",
    "ax.plot(pred, label='Prediction')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
