{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "ML",
      "language": "python",
      "name": "ml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "[2]Shakespeare Writing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KORshinjoonghyeok/DL/blob/master/%5B2%5DShakespeare_Writing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iq0VD0YmBen"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETx3aNkjmBeq"
      },
      "source": [
        "###### 데이터셋 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEOeQKbpmBeq",
        "outputId": "cdabf8e0-6403-4d83-fe49-f9195b705635",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1122304/1115394 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PK2Gd6tumBet"
      },
      "source": [
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLcHqYU0mBev",
        "outputId": "0800973a-ae82-4125-f54f-38a13ac58c64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "print(text[:200])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ksr6T7pmBey"
      },
      "source": [
        "###### 화이트 스페이스 포함 출력"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8s0mm33mBey",
        "outputId": "af49fc0e-e523-4db8-a6c7-6b073304b7e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(repr(text[:200]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4W402ULomBe0",
        "outputId": "c224a1d1-1c06-4c09-a2b6-125e64d2aa26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#총 문장 길이\n",
        "len(text)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1115394"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lndYTy4QmBe2"
      },
      "source": [
        "###### 데이터셋의 텍스트를 정렬후 vocab에 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGDPHWw0mBe3"
      },
      "source": [
        "vocab = sorted(set(text))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YinM0O17mBe5",
        "outputId": "8fcd1763-a5fc-4562-b6a2-c404e4f90413",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab[:10]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNHqOWaHmBe7"
      },
      "source": [
        "###### 텍스트에 총 사용된 캐릭터 갯수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1YGeisMmBe8",
        "outputId": "f585fee0-4c97-46d5-e451-379e60f59b93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxVWkSTPmBe-"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6S9X6vrTmBe-"
      },
      "source": [
        "##### 각 캐릭터에 인덱스 부여\n",
        "######  -  enumerate : 순서가 있는 자료형의 index번호 와 index값 을 반환하는 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7gim826mBe-"
      },
      "source": [
        "char2idx = {u: i for i, u in enumerate(vocab)}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BOC3xbpmBfA",
        "outputId": "175693dd-8993-406d-c2bd-f3ee6577bfd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "char2idx"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '$': 3,\n",
              " '&': 4,\n",
              " \"'\": 5,\n",
              " ',': 6,\n",
              " '-': 7,\n",
              " '.': 8,\n",
              " '3': 9,\n",
              " ':': 10,\n",
              " ';': 11,\n",
              " '?': 12,\n",
              " 'A': 13,\n",
              " 'B': 14,\n",
              " 'C': 15,\n",
              " 'D': 16,\n",
              " 'E': 17,\n",
              " 'F': 18,\n",
              " 'G': 19,\n",
              " 'H': 20,\n",
              " 'I': 21,\n",
              " 'J': 22,\n",
              " 'K': 23,\n",
              " 'L': 24,\n",
              " 'M': 25,\n",
              " 'N': 26,\n",
              " 'O': 27,\n",
              " 'P': 28,\n",
              " 'Q': 29,\n",
              " 'R': 30,\n",
              " 'S': 31,\n",
              " 'T': 32,\n",
              " 'U': 33,\n",
              " 'V': 34,\n",
              " 'W': 35,\n",
              " 'X': 36,\n",
              " 'Y': 37,\n",
              " 'Z': 38,\n",
              " 'a': 39,\n",
              " 'b': 40,\n",
              " 'c': 41,\n",
              " 'd': 42,\n",
              " 'e': 43,\n",
              " 'f': 44,\n",
              " 'g': 45,\n",
              " 'h': 46,\n",
              " 'i': 47,\n",
              " 'j': 48,\n",
              " 'k': 49,\n",
              " 'l': 50,\n",
              " 'm': 51,\n",
              " 'n': 52,\n",
              " 'o': 53,\n",
              " 'p': 54,\n",
              " 'q': 55,\n",
              " 'r': 56,\n",
              " 's': 57,\n",
              " 't': 58,\n",
              " 'u': 59,\n",
              " 'v': 60,\n",
              " 'w': 61,\n",
              " 'x': 62,\n",
              " 'y': 63,\n",
              " 'z': 64}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KLbfMWOmBfD"
      },
      "source": [
        "##### index -> Char"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iENN3sjzmBfD"
      },
      "source": [
        "idx2char = np.array(vocab)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpNoCV4-mBfF"
      },
      "source": [
        "###### - 49번째 index에 해당하는 char = 'k'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSmq0ZnSmBfF",
        "outputId": "8047d546-2ff7-4b4e-9d57-2375ef9f4d8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "idx2char[49]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'k'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8HSpzpomBfI",
        "outputId": "0eb81acb-e567-4480-9b66-fae8471a60c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "text[:200]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0Mf3pdbmBfK",
        "outputId": "13a36196-c646-4d89-98ec-834f13ca4ffa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "char2idx['i']"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zb-qr97imBfM"
      },
      "source": [
        "###### 전체 text -> int"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPWQQ2mFmBfM"
      },
      "source": [
        "text_as_int = np.array([char2idx[c] for c in text])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sh78JgormBfO"
      },
      "source": [
        "###### - 총 문자열 길이와 동일"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRoWwrh_mBfP",
        "outputId": "0958b2dd-243e-4080-8d06-05b3619e1305",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(text_as_int)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1115394"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUYZnJbamBfR",
        "outputId": "46bc548e-b909-4336-decf-cb58924e2ca0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text_as_int[:10]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([18, 47, 56, 57, 58,  1, 15, 47, 58, 47])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__i8ynZSmBfS"
      },
      "source": [
        "###### - 원본 문자열과 변환된 시퀀스 비교"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Qw_oclxmBfT",
        "outputId": "8588abd1-5bf9-41bf-80c4-ae3e8b6150ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#원본 문자열과 변환된 시퀀스\n",
        "print(text[:5],text_as_int[:5])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First [18 47 56 57 58]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_QaaL6BmBfU",
        "outputId": "fbd206db-9cee-4589-bcb2-c439ad437443",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#단어사전 출력\n",
        "char2idx['F'],char2idx['i'],char2idx['r'],char2idx['s'],char2idx['t']"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18, 47, 56, 57, 58)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf2zaQpNmBfW"
      },
      "source": [
        "###### - 동일"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqLaqZV8mBfW"
      },
      "source": [
        "---\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoQfIM02mBfX"
      },
      "source": [
        "###### Generate X,y dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVbpianDmBfX"
      },
      "source": [
        "# 단일 입력에 대해 원하는 문장의 최대길이\n",
        "window_size = 100\n",
        "shuffle_buffer = 10000\n",
        "batch_size=64"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPSVnW2imBfZ"
      },
      "source": [
        "###### if 'h','e','l','l'\n",
        "###### pred 'e','l','l','o'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5B52hXmcmBfZ"
      },
      "source": [
        "def windowed_dataset(series, window_size, shuffle_buffer, batch_size):\n",
        "    series = tf.expand_dims(series, -1) #차원 확장\n",
        "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
        "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True) #윈도우사이즈 +1\n",
        "    ds = ds.flat_map(lambda x: x.batch(window_size + 1))\n",
        "    ds = ds.shuffle(shuffle_buffer)\n",
        "    ds = ds.map(lambda x: (x[:-1], x[1:]))\n",
        "    return ds.batch(batch_size).prefetch(1)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJTLBmpRmBfa"
      },
      "source": [
        "train_data = windowed_dataset(np.array(text_as_int), window_size, shuffle_buffer, batch_size)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5N0QXS9mBfd",
        "outputId": "6a4b0e96-f20b-48f1-d4a0-0aa49ddf0940",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab_size = len(vocab)\n",
        "vocab_size"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4R6XFoGmBff"
      },
      "source": [
        "#임베딩할 vector차원\n",
        "embedding_dim = 256\n",
        "\n",
        "# RNN unit count\n",
        "rnn_units = 1024"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te38ujB4mBfh"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.LSTM(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3SySXpbmBfi",
        "outputId": "85e51e16-064a-4976-8120-fd50efd17298",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (64, None, 256)           16640     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (64, None, 1024)          5246976   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (64, None, 65)            66625     \n",
            "=================================================================\n",
            "Total params: 5,330,241\n",
            "Trainable params: 5,330,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6g3hyWymBfk"
      },
      "source": [
        "checkpoint_path = './models/my_checkpt.ckpt'\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    save_weights_only=True, \n",
        "    save_best_only=True,\n",
        "    monitor='loss', \n",
        "    verbose=1, \n",
        ")"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vqg2Nyb7mBfm"
      },
      "source": [
        "def loss(labels, logits):\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True) "
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMyOA1scmBfo"
      },
      "source": [
        "model.compile(optimizer='adam', loss=loss, metrics=['acc'])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-3uvQ69mBfp"
      },
      "source": [
        "###### fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "vq_u5WoImBfq",
        "outputId": "6ba16628-9293-4dbf-aa9f-e3b409eaf064",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        }
      },
      "source": [
        "model.fit(train_data, \n",
        "          epochs=10, \n",
        "          steps_per_epoch=1720, \n",
        "          callbacks=[checkpoint_callback])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1720/1720 [==============================] - ETA: 0s - loss: 0.6968 - acc: 0.8255\n",
            "Epoch 00001: loss improved from inf to 0.69684, saving model to ./models/my_checkpt.ckpt\n",
            "1720/1720 [==============================] - 96s 56ms/step - loss: 0.6968 - acc: 0.8255\n",
            "Epoch 2/10\n",
            "1720/1720 [==============================] - ETA: 0s - loss: 0.3115 - acc: 0.9300\n",
            "Epoch 00002: loss improved from 0.69684 to 0.31148, saving model to ./models/my_checkpt.ckpt\n",
            "1720/1720 [==============================] - 95s 55ms/step - loss: 0.3115 - acc: 0.9300\n",
            "Epoch 3/10\n",
            "1720/1720 [==============================] - ETA: 0s - loss: 0.2810 - acc: 0.9364\n",
            "Epoch 00003: loss improved from 0.31148 to 0.28099, saving model to ./models/my_checkpt.ckpt\n",
            "1720/1720 [==============================] - 95s 55ms/step - loss: 0.2810 - acc: 0.9364\n",
            "Epoch 4/10\n",
            "1720/1720 [==============================] - ETA: 0s - loss: 0.2809 - acc: 0.9364\n",
            "Epoch 00004: loss improved from 0.28099 to 0.28094, saving model to ./models/my_checkpt.ckpt\n",
            "1720/1720 [==============================] - 95s 55ms/step - loss: 0.2809 - acc: 0.9364\n",
            "Epoch 5/10\n",
            "1720/1720 [==============================] - ETA: 0s - loss: 0.2883 - acc: 0.9352\n",
            "Epoch 00005: loss did not improve from 0.28094\n",
            "1720/1720 [==============================] - 95s 55ms/step - loss: 0.2883 - acc: 0.9352\n",
            "Epoch 6/10\n",
            "1720/1720 [==============================] - ETA: 0s - loss: 0.2806 - acc: 0.9369\n",
            "Epoch 00006: loss improved from 0.28094 to 0.28056, saving model to ./models/my_checkpt.ckpt\n",
            "1720/1720 [==============================] - 95s 55ms/step - loss: 0.2806 - acc: 0.9369\n",
            "Epoch 7/10\n",
            "1720/1720 [==============================] - ETA: 0s - loss: 0.2923 - acc: 0.9348\n",
            "Epoch 00007: loss did not improve from 0.28056\n",
            "1720/1720 [==============================] - 95s 55ms/step - loss: 0.2923 - acc: 0.9348\n",
            "Epoch 8/10\n",
            "1720/1720 [==============================] - ETA: 0s - loss: 0.2980 - acc: 0.9338\n",
            "Epoch 00008: loss did not improve from 0.28056\n",
            "1720/1720 [==============================] - 95s 55ms/step - loss: 0.2980 - acc: 0.9338\n",
            "Epoch 9/10\n",
            "1720/1720 [==============================] - ETA: 0s - loss: 0.2966 - acc: 0.9342\n",
            "Epoch 00009: loss did not improve from 0.28056\n",
            "1720/1720 [==============================] - 96s 56ms/step - loss: 0.2966 - acc: 0.9342\n",
            "Epoch 10/10\n",
            "1720/1720 [==============================] - ETA: 0s - loss: 0.3022 - acc: 0.9330\n",
            "Epoch 00010: loss did not improve from 0.28056\n",
            "1720/1720 [==============================] - 96s 56ms/step - loss: 0.3022 - acc: 0.9330\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6de881d5f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89D4wrP2mBfr"
      },
      "source": [
        "#모델 재정의\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[1, None]),\n",
        "    tf.keras.layers.LSTM(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrY6x2nymBft",
        "outputId": "45536639-7a09-4b8f-d8f0-06a3d7a2410b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.load_weights(checkpoint_path)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f6d8c11e2b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdkui8XVmBfv"
      },
      "source": [
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-pm0MoymBfz",
        "outputId": "b4ea8146-d4c2-4fb9-8114-92c96201b3e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (1, None, 256)            16640     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (1, None, 1024)           5246976   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (1, None, 65)             66625     \n",
            "=================================================================\n",
            "Total params: 5,330,241\n",
            "Trainable params: 5,330,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6C0dCjzmBf0"
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "    # 평가 단계 (학습된 모델을 사용하여 텍스트 생성)\n",
        "\n",
        "    # 생성할 문자의 수\n",
        "    num_generate = 1000\n",
        "\n",
        "    # 시작 문자열을 숫자로 변환(벡터화)\n",
        "    input_eval = [char2idx[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "    # 결과를 저장할 빈 문자열\n",
        "    text_generated = []\n",
        "\n",
        "    # 온도가 낮으면 더 예측 가능한 텍스트가 됩니다.\n",
        "    # 온도가 높으면 더 의외의 텍스트가 됩니다.\n",
        "    # 최적의 세팅을 찾기 위한 실험\n",
        "    temperature = 1.0\n",
        "\n",
        "    # 여기에서 배치 크기 == 1\n",
        "    model.reset_states()\n",
        "    for i in range(num_generate):\n",
        "        predictions = model(input_eval)\n",
        "        # 배치 차원 제거\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "        # 범주형 분포를 사용하여 모델에서 리턴한 단어 예측\n",
        "        predictions = predictions / temperature\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "        # 예측된 단어를 다음 입력으로 모델에 전달\n",
        "        # 이전 은닉 상태와 함께\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "        text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "    return (start_string + ''.join(text_generated))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ObdDhPYmBf2",
        "outputId": "e639dd2d-7364-4702-a004-833f5cb95819",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        }
      },
      "source": [
        "print(generate_text(model, start_string=u\"FLOWER \"))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FLOWER EDWARD IV:\n",
            "Brother of Gloucester, and give our satisfied?\n",
            "\n",
            "QUEEN MARGARET:\n",
            "Mine, such as IV:\n",
            "No, God forbid that I should wish them sever'd\n",
            "Whom God hath join'd together; ay, and 'twere pity\n",
            "To su.\n",
            "\n",
            "PRING EDWARD IV:\n",
            "Now, brother of LErrown him ere't be long.'\n",
            "\n",
            "KING EDWARD IV:\n",
            "Ha! durst the traitor breathe Sixth claim England:\n",
            "And Warwick, follow me, being thou canst do what I mean to ask.\n",
            "\n",
            "LADY GREY:\n",
            "Why, then I will do what your grace commands.\n",
            "\n",
            "GLOUCESTER:\n",
            "\n",
            "KING EDWARD IV:\n",
            "Now, messenger, what letto do a dangerous honour,\n",
            "Or than for strength and safety of our country.\n",
            "\n",
            "BONA:\n",
            "Dear brother, how shall Bona be revenged\n",
            "But by thy heart Lord Bowhat of France is sending over masquers\n",
            "To respector the naprest,\n",
            "And but stancil say nd himself-gle like short is he thought with him\n",
            "And prince shall foe:\n",
            "I speak no more than what let thy dauntleash to be quite alsewis of France;\n",
            "How could he stay till Warwick made a seem to our coox Margaret,\n",
            "With this my son, Prince Edward, Henry's heir,\n",
            "Am co\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfHx2EhyqqHM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}